import os
import json
import joblib
import numpy as np
import xgboost as xgb
from sklearn.ensemble import IsolationForest

# Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª
os.makedirs("ml_artifacts", exist_ok=True)
os.makedirs("cache", exist_ok=True)

print("ğŸš€ Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ù…ØµÙ†Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„Ù†Ù…Ø§Ø°Ø¬...")

# ---------------------------------------------------------
# 1. Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø´Ø¨ÙƒØ© Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠØ© (Ù„Ù„Ø¹Ù‚Ù„ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠ)
# ---------------------------------------------------------
print("ğŸ§  Ø¬Ø§Ø±ÙŠ Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø´Ø¨ÙƒØ© Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠØ© (Semantic Net)...")
semantic_net = {
    "SECTORS": {
        "TSLA": "EV_TECH",
        "AAPL": "CONSUMER_ELECTRONICS",
        "NVDA": "SEMICONDUCTORS",
        "2222.SR": "ENERGY_OIL",
        "ARAMCO": "ENERGY_OIL",
        "BTC-USD": "CRYPTOCURRENCY"
    },
    "RELATIONS": {
        "EV_TECH": ["Interest Rates", "Battery Cost", "AI Regulation"],
        "ENERGY_OIL": ["OPEC", "Geopolitics", "Global Demand"],
        "CRYPTOCURRENCY": ["SEC Regulation", "Tech Sentiment", "Inflation"]
    }
}
with open("cache/semantic_net.json", "w", encoding="utf-8") as f:
    json.dump(semantic_net, f, ensure_ascii=False, indent=4)
print("   âœ… ØªÙ… Ø­ÙØ¸: cache/semantic_net.json")

# ---------------------------------------------------------
# 2. Ø¨Ù†Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø®Ø§Ø·Ø± (XGBoost Crash Predictor)
# ---------------------------------------------------------
print("ğŸ“‰ Ø¬Ø§Ø±ÙŠ ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ ÙƒØ´Ù Ø§Ù„Ø§Ù†Ù‡ÙŠØ§Ø± (XGBoost)...")
# Ø¨ÙŠØ§Ù†Ø§Øª ÙˆÙ‡Ù…ÙŠØ© Ù„Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø£ÙˆÙ„ÙŠ
X = np.random.rand(100, 3) # [RSI, Volatility, Trend]
y = np.random.randint(0, 2, 100) # [0: Safe, 1: Crash]

xgb_model = xgb.XGBClassifier(n_estimators=10, max_depth=3)
xgb_model.fit(X, y)
xgb_model.save_model("ml_artifacts/xgb_crash.json")
print("   âœ… ØªÙ… Ø­ÙØ¸: ml_artifacts/xgb_crash.json")

# ---------------------------------------------------------
# 3. Ø¨Ù†Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¯ÙØ§Ø¹ (Isolation Forest)
# ---------------------------------------------------------
print("ğŸ›¡ï¸ Ø¬Ø§Ø±ÙŠ ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¯ÙØ§Ø¹ (Sanitizer)...")
# Ø¨ÙŠØ§Ù†Ø§Øª Ø·Ø¨ÙŠØ¹ÙŠØ©
X_normal = np.random.normal(100, 10, (200, 1))
iso_model = IsolationForest(contamination=0.05)
iso_model.fit(X_normal)
joblib.dump(iso_model, "ml_artifacts/isolation_forest.pkl")
print("   âœ… ØªÙ… Ø­ÙØ¸: ml_artifacts/isolation_forest.pkl")

print("\nğŸ‰ Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ¬Ù‡ÙŠØ²! Ø§Ù„Ù†Ø¸Ø§Ù… Ø¬Ø§Ù‡Ø² Ø§Ù„Ø¢Ù† Ù„Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ ÙƒÙˆØ¯ Ø§Ù„Ù…Ù†Ø·Ù‚.")