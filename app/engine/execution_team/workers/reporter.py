from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from app.core.config import settings

# Ù†Ø³ØªØ®Ø¯Ù… Ø¯Ø±Ø¬Ø© Ø­Ø±Ø§Ø±Ø© Ù…Ù†Ø®ÙØ¶Ø© Ù„Ù„Ø¯Ù‚Ø©
llm = ChatOpenAI(model="gpt-4o-mini", api_key=settings.OPENAI_API_KEY, temperature=0.3)

# ğŸ”´ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ù‡Ù†Ø§: ØªØºÙŠÙŠØ± Ø§Ø³Ù… Ø§Ù„Ø¯Ø§Ù„Ø© Ù…Ù† writer_node Ø¥Ù„Ù‰ reporter_node
def reporter_node(state):
    """
    Ø¹Ø§Ù…Ù„ Ø§Ù„ÙƒØªØ§Ø¨Ø© (Reporter Worker).
    Ø§Ù„Ù…Ù‡Ù…Ø©: ØªØ¬Ù…ÙŠØ¹ ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„ÙØ±ÙŠÙ‚ ÙˆØµÙŠØ§ØºØ© Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ.
    """
    print("--- ğŸ“ Reporter: ØµÙŠØ§ØºØ© Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø§Ù„Ù…ÙˆØ­Ø¯ ---")
    
    symbol = state.get('symbol')
    
    # Ø¬Ù„Ø¨ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„ÙØ±Ø¹ÙŠØ©
    fund_summary = state.get('fundamental_summary', 'Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ø³Ø§Ø³ÙŠØ© ØºÙŠØ± Ù…ØªÙˆÙØ±Ø©.')
    tech_report = state.get('technical_report', 'Ø¨ÙŠØ§Ù†Ø§Øª ÙÙ†ÙŠØ© ØºÙŠØ± Ù…ØªÙˆÙØ±Ø©.')
    
    sent_data = state.get('sentiment_report', {})
    if isinstance(sent_data, dict):
        sent_summary = sent_data.get('summary', 'Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø®Ø¨Ø§Ø±.')
        sent_score = sent_data.get('score', 0)
    else:
        sent_summary = "Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø´Ø§Ø¹Ø± ØºÙŠØ± ÙˆØ§Ø¶Ø­Ø©."
        sent_score = 0
    
    defense_summary = state.get('defense_report', 'Ù„Ù… ÙŠØªÙ… Ø¥Ø¬Ø±Ø§Ø¡ ÙØ­Øµ Ø£Ù…Ù†ÙŠ.')

    # Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ø£Ù…Ø±
    prompt = PromptTemplate.from_template("""
    Ø£Ù†Øª Ø±Ø¦ÙŠØ³ Ù‚Ø³Ù… Ø§Ù„Ø£Ø¨Ø­Ø§Ø« ÙÙŠ Ù…Ø¤Ø³Ø³Ø© Ù…Ø§Ù„ÙŠØ© ÙƒØ¨Ø±Ù‰.
    Ù„Ø¯ÙŠÙƒ Ù…Ø³ÙˆØ¯Ø§Øª ÙˆØªÙ‚Ø§Ø±ÙŠØ± Ù…Ù† ÙØ±ÙŠÙ‚ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ø®ØµÙˆØµ Ø³Ù‡Ù…: {symbol}.
    
    Ù…Ù‡Ù…ØªÙƒ: Ø¯Ù…Ø¬ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ØªÙØ±Ù‚Ø© ÙÙŠ ØªÙ‚Ø±ÙŠØ± Ø§Ø³ØªØ«Ù…Ø§Ø±ÙŠ ÙˆØ§Ø­Ø¯ØŒ Ù…ØªÙ…Ø§Ø³ÙƒØŒ ÙˆØ§Ø­ØªØ±Ø§ÙÙŠ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.
    
    --- Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙˆØ§Ø±Ø¯Ø© ---
    1. ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ù…Ø§Ù†: {defense_summary}
    2. Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ: {fund_summary}
    3. Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ: {tech_report}
    4. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± (Score: {sent_score}): {sent_summary}
    
    --- Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ---
    Ø§ÙƒØªØ¨ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø¨ØªÙ†Ø³ÙŠÙ‚ Markdown Ø¨Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„ØªØ§Ù„ÙŠØ©:
    ### ğŸ“Š Ø§Ù„Ù…Ù„Ø®Øµ ÙˆØ§Ù„ØªÙˆØµÙŠØ©
    (Ø´Ø±Ø§Ø¡/Ø¨ÙŠØ¹/Ø§Ù†ØªØ¸Ø§Ø± Ù…Ø¹ Ø§Ù„Ø³Ø¨Ø¨).
    ### ğŸ¢ Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ù…Ø§Ù„ÙŠ
    ### ğŸ“ˆ Ø§Ù„ØªÙˆÙ‚ÙŠØª Ø§Ù„ÙÙ†ÙŠ ÙˆÙ†Ø¨Ø¶ Ø§Ù„Ø³ÙˆÙ‚
    ### âš ï¸ Ø§Ù„Ù…Ø®Ø§Ø·Ø±
    """)
    
    chain = prompt | llm
    result = chain.invoke({
        "symbol": symbol,
        "defense_summary": defense_summary,
        "fund_summary": fund_summary,
        "tech_report": tech_report,
        "sent_summary": sent_summary,
        "sent_score": sent_score
    })
    
    final_text = result.content
    
    return {
        "final_report": final_text 
    }